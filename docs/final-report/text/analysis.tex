Analysis of our results shows that the entire system works convincingly well enough,
serving our original objective of automated slide generation.
The output generated by the system is a good starting point, with all structural
information - like paper details, author details, section hierarchy, the summary of every
section, relevant images and citations - in place.
The parser was versatile enough to reconstruct proper structure from a majority of the HTML
dumps of the papers from the dataset.
Also as noted by \cite{sravanthi}, purely statistical methods were good enough to obtain a
minimum level of coherence and information during summarization.
The various methods of the summarizer like keyword expansion through co-occurance frequencies and
evaluating importance of lines using TF-IDF like similarities with abstract and keywords, boosting
lines with tagged images, etc. never produced irrelevant summaries.
The combination of various deterministic as well herusitic rules we applied at each
stage of our pipeline worked well together to give an output that is both information preserving
as well as aesthetically pleasing.
